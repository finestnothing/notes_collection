source:: [Databricks Data Science and Engineering workspace](https://customer-academy.databricks.com/learn/course/1092/play/5761/what-is-databricks-data-science-and-engineering-workspace;lp=10)

# 202210111603
Created: 2022-10-11 16:03

- What's in the data science and engineering workspace
	- notebooks
		- Queries data
		- Run other notebooks and stuff
		- Interactive or batch
	- folders
		- Organizes notebooks and stuff
	- repos
		- Sync files and notebooks to remote repository
		- API for integrating with others
	- secrets
		- Secure key-value storage
	- jobs
		- Run tasks, either 1 or multiple
		- Run Notebooks, applications, jars, pipelines, spark submit style
	- pipelines
		- Delta live tables
		- Pipeline is implemented through pipelines defining source in notebooks
	- clusters
	- pools
		- Reduce pool and cluster start times
		- Keeps idle instances for faster startup
- Workflow
	- Create a notebook
	- Create or attach to a cluster
	- The cluster will run the commands on the data
	- Run the notebook with a scheduled job, or if it's a pipeline delta live tables run the pipeline
	- Notebook can be moved to a repo for git integration
- Data tab  displays tables that the cluster you're attached to can access
- Workflows
	- Schedule and use jobs and pipelines
- Clusters
	- Can connect to a catalog
- To view job run details
	- Navigate to workflows page
	- Access job run details from the "Runs" tab for the job