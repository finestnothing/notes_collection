# 202206160649
Created: 2022-06-16 06:49

- Page 161
	- Regularization
		- The point of regularization is to reduce the factors being considered
		- The factors with a small overall impact/correlation are driven to 0 (to no longer matter) while the factors that do have a large impact are not
	- Over-fitting
		- Over-fitting is when we use too much data or training and it ends up becoming less accurate than more
		- I.E. predicting it drops off sharply due to using 9 functions
- Page 164
	- Humans have a cross wired nervous system (right brain - left body) because vertebrates used to have their heads 180 degrees from how they currently are at some point in evolution
- Page 167
	- Thinking less
	- If you have high uncertainty and low data, stop early!
		- The more precise you try to get, the more that you need a lot of data and high certainty about what you're measuring your outcome with
		- Good example is sketching
			- Initial sketch is done in a large pen, it's a thicker stroke and lets you focus on the overall details rather than very small ones
			- As you get further into the sketch or idea, you can slowly move to using a precise pen, getting every curve and bump just right

## References
1. algorithms_to_live_by - Chapter 7